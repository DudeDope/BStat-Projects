{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "bSVBlS6f1rs6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LisbJWu5z4oU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters"
      ],
      "metadata": {
        "id": "B3-lU6yF10_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 784      # Omniglot images are 28x28 (flattened to 784)\n",
        "D = 64               # Hidden dimension for attributes\n",
        "z_dim = 64           # Task representation dimension\n",
        "mu = 0.1             # Regularization parameter\n",
        "lambda_ = 0.01       # Soft thresholding parameter\n",
        "num_inner_iter = 5   # Inner loop iterations\n",
        "lr = 1e-3            # Learning rate\n",
        "num_epochs = 10      # Training epochs\n",
        "support_size = 10    # Support set size per task\n",
        "query_size = 10      # Query set size per task\n"
      ],
      "metadata": {
        "id": "lmByaQzf0dsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data\n"
      ],
      "metadata": {
        "id": "oGSwONFY1_yF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "data_root = \" \"\n",
        "train_dir = os.path.join(data_root, \"images_background\")\n",
        "\n",
        "# Preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x.flatten())\n",
        "])\n",
        "\n",
        "\n",
        "# Loading Data\n",
        "def load_omniglot_tasks(root_dir, num_tasks=1000):\n",
        "    \"\"\"Load Omniglot tasks without using classes.\"\"\"\n",
        "    # Get all character classes\n",
        "    alphabets = glob.glob(os.path.join(root_dir, \"*\"))\n",
        "    all_classes = []\n",
        "    for alphabet in alphabets:\n",
        "        all_classes.extend(glob.glob(os.path.join(alphabet, \"*\")))\n",
        "\n",
        "    # Generating tasks\n",
        "    tasks = []\n",
        "    for _ in range(num_tasks):\n",
        "        # selecting normal and anomaly classes\n",
        "        normal_idx = np.random.randint(len(all_classes))\n",
        "        normal_class = all_classes[normal_idx]\n",
        "        anomaly_classes = [\n",
        "            c for c in all_classes\n",
        "            if c != normal_class\n",
        "        ][:5]\n",
        "\n",
        "        # Loading support set (normal class)\n",
        "        support_files = glob.glob(os.path.join(normal_class, \"*\"))[:support_size]\n",
        "        support_set = [transform(Image.open(f).convert('L')) for f in support_files]\n",
        "\n",
        "        # Loading query set\n",
        "        query_normal_files = glob.glob(os.path.join(normal_class, \"*\"))[support_size:support_size + query_size//2]\n",
        "        query_normal = [transform(Image.open(f).convert('L')) for f in query_normal_files]\n",
        "\n",
        "        query_anomaly = []\n",
        "        for c in anomaly_classes:\n",
        "            files = glob.glob(os.path.join(c, \"*\"))[:query_size//(2*len(anomaly_classes))]\n",
        "            query_anomaly.extend([transform(Image.open(f).convert('L')) for f in files])\n",
        "\n",
        "        tasks.append((\n",
        "            torch.stack(support_set),\n",
        "            torch.stack(query_anomaly),\n",
        "            torch.stack(query_normal)\n",
        "        ))\n",
        "    return tasks\n",
        "\n",
        "tasks = load_omniglot_tasks(train_dir, num_tasks=1000)\n",
        "\n"
      ],
      "metadata": {
        "id": "zGFbpCoJ0e1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining functions"
      ],
      "metadata": {
        "id": "8aNtqn692whN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task encoder (f)\n",
        "task_encoder = nn.Sequential(\n",
        "    nn.Linear(input_dim, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, z_dim)\n",
        ")\n",
        "\n",
        "# Network h\n",
        "h_network = nn.Sequential(\n",
        "    nn.Linear(input_dim + z_dim, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, D)\n",
        ")\n",
        "\n",
        "# Network v\n",
        "v_network = nn.Sequential(\n",
        "    nn.Linear(input_dim + z_dim, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, D)\n",
        ")\n",
        "\n",
        "# Learnable parameters\n",
        "mu_param = nn.Parameter(torch.tensor(mu))\n",
        "lambda_param = nn.Parameter(torch.tensor(lambda_))\n",
        "\n",
        "# Combining all parameters\n",
        "params = list(task_encoder.parameters()) + \\\n",
        "         list(h_network.parameters()) + \\\n",
        "         list(v_network.parameters()) + \\\n",
        "         [mu_param, lambda_param]\n",
        "\n",
        "optimizer = optim.Adam(params, lr=lr)\n",
        "\n",
        "def compute_scores(support_set, query_set):\n",
        "    # Computing task representation z\n",
        "    embeddings = torch.stack([task_encoder(x) for x in support_set])\n",
        "    z = torch.mean(embeddings, dim=0)\n",
        "\n",
        "    # Initial attribute A0\n",
        "    A = torch.stack([v_network(torch.cat([x, z])) for x in support_set])\n",
        "\n",
        "    W = None\n",
        "    for _ in range(num_inner_iter):\n",
        "        H = torch.stack([h_network(torch.cat([x, z])) for x in support_set])\n",
        "        X = torch.stack(support_set)\n",
        "        N_S = len(support_set)\n",
        "\n",
        "        # Updating W\n",
        "        HtH = H.T @ H / N_S\n",
        "        reg_matrix = mu_param * torch.eye(H.shape[1])\n",
        "        inv = torch.inverse(HtH + reg_matrix)\n",
        "        W = inv @ (H.T @ X) / N_S\n",
        "\n",
        "        # Updating A\n",
        "        residual = X - W @ H.T\n",
        "        threshold = lambda_param / mu_param\n",
        "        A = torch.sign(residual) * torch.relu(torch.abs(residual) - threshold)\n",
        "\n",
        "    # Computing scores\n",
        "    scores = []\n",
        "    for x in query_set:\n",
        "        h_xz = h_network(torch.cat([x, z]))\n",
        "        recon = W @ h_xz\n",
        "        scores.append(torch.norm(x - recon, p=2)**2)\n",
        "    return torch.stack(scores)"
      ],
      "metadata": {
        "id": "979oY5I-2w43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n"
      ],
      "metadata": {
        "id": "f1seIMpX3BdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for support, query_anomaly, query_normal in tasks:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Computing scores\n",
        "        anomaly_scores = compute_scores(support, query_anomaly)\n",
        "        normal_scores = compute_scores(support, query_normal)\n",
        "\n",
        "        # Smoothed AUC\n",
        "        diff = anomaly_scores.unsqueeze(1) - normal_scores.unsqueeze(0)\n",
        "        auc = torch.sigmoid(diff).mean()\n",
        "        loss = 1 - auc\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch}, Loss: {total_loss / len(tasks)}\")"
      ],
      "metadata": {
        "id": "gyId1LZc3CLE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}